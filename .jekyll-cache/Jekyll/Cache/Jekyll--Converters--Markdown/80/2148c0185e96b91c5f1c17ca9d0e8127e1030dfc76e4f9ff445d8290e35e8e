I"¢<h1 id="news--activities">News &amp; Activities</h1>
<p><strong>May 1, 2021:</strong> Today, I started as a postdoctoral fellow at the <a href="https://www.ualberta.ca/index.html">University of Alberta</a>. Iâ€™m working with <a href="http://webdocs.cs.ualberta.ca/~bowling/index.html">Michael Bowling</a> in the <a href="http://rlai.ualberta.ca">RLAI Lab</a>, studying artifical intelligence and decision making.</p>

<p><strong>April 26, 2021:</strong> I sucessfully defended my PhD thesis: Reinforcement Learning Algorithms for Representing and Managing Uncertainty in Robotics.</p>

<p><strong>November 10, 2020:</strong> I gave a virtual talk to the <a href="http://rail.eecs.berkeley.edu">RAIL group</a> at UC Berkeley.</p>

<p><strong>July 1, 2020:</strong> Three projects with which I was involved have been accepted for publication at the <a href="https://www.iros2020.org">International Conference on Intelligent Robots and Systems (IROS)</a>.</p>

<p>Variational Filtering with Copula Models for SLAM<br />
<strong>John D. Martin</strong>*, Kevin Doherty*, Caralyn Cyr, Brendan Englot, John Leonard. [<a href="https://arxiv.org/abs/2008.00504">paper</a>]</p>

<p>Autonomous Exploration Under Uncertainty via Deep Reinforcement Learning on Graphs<br />
Fanfei Chen, <strong>John D. Martin</strong>, Yewei Huang, Jinkun Wang, Brendan Englot. [<a href="https://arxiv.org/abs/2007.12640">paper</a>]</p>

<p>Fusing Concurrent Orthogonal Wide-aperture Sonar Images for Dense Underwater 3D Reconstruction<br />
John McConnell, <strong>John D. Martin</strong>, Brendan Englot. [<a href="https://arxiv.org/abs/2007.10407">paper</a>]</p>

<p><strong>June 1, 2020:</strong> Our paper <a href="https://arxiv.org/abs/1905.07318">Stochastically Dominant Distributional Reinforcement Learning</a> was accepted to the <a href="https://icml.cc">International Conference on Machine Learning (ICML)</a>! [<a href="https://arxiv.org/abs/1905.07318">paper</a>]</p>

<p><strong>May 1, 2020:</strong> Iâ€™m giving a guest lecture on uncertainty-aware reinforcement learning to the advanced robotics class for graduate students at Stevens Institute of Technology. [<a href="/assets/slides/2020-advanced_robotics_lecture.pdf">slides</a>]</p>

<p><strong>March 13, 2020:</strong> Today I am showcasing my work on uncertainy-aware decision making as part of the <a href="https://www.nyas.org/events/2020/14th-annual-machine-learning-symposium/">New York Academy of Sciencesâ€™ 14th annual Machine Learning Symposium</a>. [<a href="/assets/posters/2020-martin_etal-poster.pdf">poster</a>]</p>

<p><strong>January 27, 2020:</strong> I am thrilled to announce that I will be working at <a href="https://deepmind.com">DeepMind</a> in Edmonton, Canada, as a research intern with <a href="https://scholar.google.com/citations?user=G3pvUNEAAAAJ&amp;hl=en">Joseph Modayil</a>. There I plan to study perception and discovery in the context of continual reinforcement learning.</p>

<p><strong>November 4, 2019:</strong> Visiting MIT to connect with <a href="https://tixiaoshan.github.io">Tixiao Shan</a> at <a href="https://www.csail.mit.edu">CSAIL</a> and learn about the <a href="http://roboat.org">Roboat project</a>. Iâ€™m giving a short talk to the group about my recent work.</p>

<p><strong>October 22, 2019:</strong> Iâ€™m giving a talk at <a href="http://deepmind.com">DeepMind</a> in Edmonton, Canada, about how RL agents can benefit from organizing their experience into contexts.</p>

<p><strong>October 7, 2019:</strong> Two of my projects will appear as NeurIPS workshop papers this year.Â Â </p>
<ul>
  <li><a href="https://sites.google.com/view/neurips19-safe-robust-workshop#h.p_iF36C6BL_elR">Saftey and Robust Decison Making Workshop</a>: Stochastically Dominant Distributional Reinforcement Learning, <strong>John D. Martin</strong>, Â Michal Lyskawinski, Xiaohu Li, Brendan Englot.Â Â </li>
  <li><a href="https://sites.google.com/view/biologicalandartificialrl">Biological and Artifical RL Workshop</a>: Memento: Further Progress through Forgetting, William Fedus, Dibya Ghosh, <strong>John D. Martin</strong>, Marc G. Bellemare, Hugo Larochelle, Yoshua Bengio.</li>
</ul>

<p><strong>September 18, 2019:</strong> Iâ€™m giving a talk about the disparate impacts of alpine climbing as part of the <a href="https://americanalpineclub.org">American Alpine Club</a>â€™s Story Swap in Philadelphia <a href="https://www.phillychapter-aac.org/journal/2019/9/06/john">[link]</a>.</p>

<p><strong>August 30, 2019:</strong> Iâ€™m giving a talk at <a href="https://ai.google/research/teams/brain/robotics/">Google Robotics</a> in New York City on exploiting transition invariance for efficient Reinforcement Learning in multi-stage settings.</p>

<p><strong>July 19, 2019:</strong> I was featured in the journal of the <a href="https://americanalpineclub.org">American Alpine Club</a>â€™s Philadelphia chapter, as part of my work with their winter mountaineering mentorship program <a href="https://www.phillychapter-aac.org/journal/2019/6/29/mentoring-program-spotlight-john-martin">[link]</a>.</p>

<p><strong>March 14, 2019:</strong> Iâ€™m excited to announce that I will be working at <a href="https://ai.google/research/teams/brain">Google Brain</a> in MontrÃ©al, Canada, as a research intern with <a href="https://scholar.google.com/citations?user=uyYPun0AAAAJ&amp;hl=en#">Marc G. Bellemare</a>â€™s group. There I will study methods for continual reinforcement learning in deep neural networks, focusing on settings with non-stationary data.</p>

:ET