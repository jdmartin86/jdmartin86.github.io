---
layout: full-width
title: About
# Note that this index page uses a full-width layout!
---
<h1 class="content-listing-header sans">John D. Martin</h1>
I’m a postdoctoral fellow researching decision making and artificial intelligence at the University of Alberta. I work with [Michael Bowling](http://webdocs.cs.ualberta.ca/~bowling/index.html), as a member of the [RLAI Lab](http://rlai.ualberta.ca). 

I obtained my PhD from Stevens Institute of Technology, where I was advised by [Prof. Brendan Englot](http://personal.stevens.edu/~benglot/). I earned undergraduate degrees in both physics and aerospace engineering from the [University of Maryland](https://umdphysics.umd.edu). I’ve also spent time at [DeepMind](https://deepmind.com), [Google Brain](https://ai.google), [Columbia University](https://www.columbia.edu), and [Sikorsky Aircraft](https://www.wired.com/story/sikorsky-sara-helicopter-autonomous-flying-car-air-taxi-tech/). See my [CV](/assets/cv/2022-martin-cv.pdf) for more details.

## Research Interests
I want to understand how to design machines that are capable of learning and making intelligent decisions. My current research pertains to questions about the generality of resource-constrained, physical learning systems.

Some specific questions I find interesting are: How can machines acquire knowledge from sensory signals whose interdependecies are unknown? 
What are useful ways learning objectives can be automatically generated and curated?
How can machines learn as efficiently as humans from physical streams of data? 
What are the inductive pathways that make efficient learning possible? When is it possible to replace inductive knowledge with adaptation or learning? What knowledge can be directly learned from a stream of sensory experience, within a practical data regime? And how can such principles be formalized and encoded into programs that solve meaningful problems? 

I believe the reinforcement learning paradigm provides a good framework from which many of these questions can be studied. In my career, I hope to address some of RL’s fundamental limitations by expanding its scope to new settings with more complex and open-ended objectives. 

Specifically, I would like to understand what logic underlies reliable generalization between different but related learning objectives, from experience collected over an indefinite period of time, and with relevance to physical embodied systems.

I’m motivated and inspired by the work of my peers in statistical machine learning, robotics, neuroscience, cognitive science, mathematical psychology, and philosophy. 

Though I wouldn’t claim RL is the only way to study decision making, I do believe that advances in RL can lead to better automated technologies and better theoretical paradigms from which others can understand human cognition and artificial intelligence.
