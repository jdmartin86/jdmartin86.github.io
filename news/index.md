---
layout: full-width
title: News
---

# News & Activities
**July 1, 2020:** Three projects with which I was involved have been accepted for publication at the [International Conference on Intelligent Robots and Systems (IROS)](https://www.iros2020.org). Preprints are forthcoming.

Variational Filtering with Copula Models for SLAM  
**John D. Martin***, Kevin Doherty\*, Caralyn Cyr, Brendan Englot, John Leonard.

Autonomous Exploration Under Uncertainty via Deep Reinforcement Learning on Graphs  
Fanfei Chen, **John D. Martin**, Yewei Huang, Jinkun Wang, Brendan Englot.

Fusing Concurrent Orthogonal Wide-aperture Sonar Images for Dense Underwater 3D Reconstruction  
John McConnell, **John D. Martin**, Brendan Englot.

**June 1, 2020:** Our paper [Stochastically Dominant Distributional Reinforcement Learning](https://arxiv.org/abs/1905.07318) was accepted to the [International Conference on Machine Learning (ICML)](https://icml.cc)! [[paper](https://arxiv.org/abs/1905.07318)]

**May 1, 2020:** I'm giving a guest lecture on uncertainty-aware reinforcement learning to the advanced robotics class for graduate students at Stevens Institute of Technology. [[slides](/assets/slides/2020-advanced_robotics_lecture.pdf)]

**March 13, 2020:** Today I am showcasing my work on uncertainy-aware decision making as part of the [New York Academy of Sciences' 14th annual Machine Learning Symposium](https://www.nyas.org/events/2020/14th-annual-machine-learning-symposium/). [[poster](/assets/posters/2020-martin_etal-poster.pdf)]
 
**January 27, 2020:** I am thrilled to announce that I will be working at [DeepMind](https://deepmind.com) in Edmonton, Canada, as a research intern with [Joseph Modayil](https://scholar.google.com/citations?user=G3pvUNEAAAAJ&hl=en). There I plan to study perception and discovery in the context of continual reinforcement learning.

**November 4, 2019:** Visiting MIT to connect with [Tixiao Shan](https://tixiaoshan.github.io) at [CSAIL](https://www.csail.mit.edu) and learn about the [Roboat project](http://roboat.org). I'm giving a short talk to the group about my recent work. 

**October 22, 2019:** I'm giving a talk at [DeepMind](http://deepmind.com) in Edmonton, Canada, about how RL agents can benefit from organizing their experience into contexts.

**October 7, 2019:** Two of my projects will appear as NeurIPS workshop papers this year.   
   * [Saftey and Robust Decison Making Workshop](https://sites.google.com/view/neurips19-safe-robust-workshop#h.p_iF36C6BL_elR): Stochastically Dominant Distributional Reinforcement Learning, **John D. Martin**,  Michal Lyskawinski, Xiaohu Li, Brendan Englot.   
   * [Biological and Artifical RL Workshop](https://sites.google.com/view/biologicalandartificialrl): Memento: Further Progress through Forgetting, William Fedus, Dibya Ghosh, **John D. Martin**, Marc G. Bellemare, Hugo Larochelle, Yoshua Bengio.

**September 18, 2019:** I'm giving a talk about the disparate impacts of alpine climbing as part of the [American Alpine Club](https://americanalpineclub.org)'s Story Swap in Philadelphia [[link]](https://www.phillychapter-aac.org/journal/2019/9/06/john).

**August 30, 2019:** I'm giving a talk at [Google Robotics](https://ai.google/research/teams/brain/robotics/) in New York City on exploiting transition invariance for efficient Reinforcement Learning in multi-stage settings.

**July 19, 2019:** I was featured in the journal of the [American Alpine Club](https://americanalpineclub.org)'s Philadelphia chapter, as part of my work with their winter mountaineering mentorship program [[link]](https://www.phillychapter-aac.org/journal/2019/6/29/mentoring-program-spotlight-john-martin). 

**March 14, 2019:** I'm excited to announce that I will be working at [Google Brain](https://ai.google/research/teams/brain) in Montréal, Canada, as a research intern with [Marc G. Bellemare](https://scholar.google.com/citations?user=uyYPun0AAAAJ&hl=en#)'s group. There I will study methods for continual reinforcement learning in deep neural networks, focusing on settings with non-stationary data.

