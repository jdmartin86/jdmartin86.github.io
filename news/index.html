<!DOCTYPE html>
<html>
  <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title>News</title>
  <meta name="description" content="">

  <!-- Google Fonts loaded here depending on setting in _data/options.yml true loads font, blank does not-->
  
    <link href='//fonts.googleapis.com/css?family=Lato:400,400italic' rel='stylesheet' type='text/css'>
  
  
  <!-- Load up MathJax script if needed ... specify in /_data/options.yml file-->
  
    <script type="text/javascript" src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
  

  <link rel="stylesheet" type="text/css" href="/css/tufte.css">
  <!-- <link rel="stylesheet" type="text/css" href="/css/print.css" media="print"> -->

  <link rel="canonical" href="/news/">

  <link rel="alternate" type="application/rss+xml" title="John D. Martin" href="/feed.xml" />
</head>

  <body class="full-width">
    <!--- Header and nav template site-wide -->
<header>
    <nav class="group">
	<a href="/"><img class="badge" src="/assets/img/badge_1.png" alt="CH"></a>
	
		
  	
		
		    
		      <a href="/research/index.html">Research</a>
		    
	    
  	
		
		    
		      <a href="/blog/index.html">Blog</a>
		    
	    
  	
		
		    
		      <a class="active" href="/news/index.html" class="active">News</a>
		    
	    
  	
		
		    
		      <a href="/climbing/index.html">Climbing</a>
		    
	    
  	
		
		    
		      <a href="/index.html">About</a>
		    
	    
  	
		
		    
		      <a href="/css/print.css"></a>
		    
	    
  	
		
  	
	</nav>
</header>
    <article>
      <h1 id="news--activities">News &amp; Activities</h1>
<p><strong>March 18, 2022:</strong> I had two papers accepted to RLDM (The Multi-disciplinary Conference on Reinforcement Learning and Decision Making).</p>

<p>Should Models Be Accurate?,<br />
Esra’a Saleh, <strong>John D. Martin</strong>, Anna Koop, Arash Pourzarabi, Michael Bowling [<a href="/assets/papers/2022_rldm_useful_models.pdf">pdf</a>]</p>

<p>Adapting the Function Approximation Architecture in Online Reinforcement Learning,<br />
<strong>John D. Martin</strong>*,  Joseph Modayil*, [<a href="/assets/papers/2022_rldm_frogs_eye.pdf">pdf</a>] [<a href="https://github.com/jdmartin86/frogseye">code</a>] [<a href="https://arxiv.org/pdf/2106.09776">full paper pdf</a>]</p>

<p><strong>February 15, 2022:</strong> I was named by the <a href="https://ieeeoes.org/publications/ieee-journal-of-oceanic-engineering/">IEEE Journal of Oceanic Engineering</a> as an Outstanding Reviewer in 2021.</p>

<p><strong>December 23, 2021:</strong> This week I am giving two lectures at the <a href="https://nepalschool.naamii.com.np">Nepal Winter AI School</a>, hosted by NAAMII. The first lecture is on introductory concepts of reinforcement learning [<a href="/assets/slides/2021-naamii-lec1.pdf">slides</a>]. The second lecture is on reinforcement learning in moderntity [<a href="/assets/slides/2021-naamii-lec2.pdf">slides</a>].</p>

<p><strong>May 1, 2021:</strong> Today, I started as a postdoctoral fellow at the <a href="https://www.ualberta.ca/index.html">University of Alberta</a>. I’m working with <a href="http://webdocs.cs.ualberta.ca/~bowling/index.html">Michael Bowling</a> in the <a href="http://rlai.ualberta.ca">RLAI Lab</a>, studying artifical intelligence and decision making.</p>

<p><strong>April 26, 2021:</strong> I sucessfully defended my PhD thesis: Reinforcement Learning Algorithms for Representing and Managing Uncertainty in Robotics.</p>

<p><strong>November 10, 2020:</strong> I gave a virtual talk to the <a href="http://rail.eecs.berkeley.edu">RAIL group</a> at UC Berkeley.</p>

<p><strong>July 1, 2020:</strong> Three projects with which I was involved have been accepted for publication at the <a href="https://www.iros2020.org">International Conference on Intelligent Robots and Systems (IROS)</a>.</p>

<p>Variational Filtering with Copula Models for SLAM<br />
<strong>John D. Martin</strong>*, Kevin Doherty*, Caralyn Cyr, Brendan Englot, John Leonard. [<a href="https://arxiv.org/abs/2008.00504">paper</a>]</p>

<p>Autonomous Exploration Under Uncertainty via Deep Reinforcement Learning on Graphs<br />
Fanfei Chen, <strong>John D. Martin</strong>, Yewei Huang, Jinkun Wang, Brendan Englot. [<a href="https://arxiv.org/abs/2007.12640">paper</a>]</p>

<p>Fusing Concurrent Orthogonal Wide-aperture Sonar Images for Dense Underwater 3D Reconstruction<br />
John McConnell, <strong>John D. Martin</strong>, Brendan Englot. [<a href="https://arxiv.org/abs/2007.10407">paper</a>]</p>

<p><strong>June 1, 2020:</strong> Our paper <a href="https://arxiv.org/abs/1905.07318">Stochastically Dominant Distributional Reinforcement Learning</a> was accepted to the <a href="https://icml.cc">International Conference on Machine Learning (ICML)</a>! [<a href="https://arxiv.org/abs/1905.07318">paper</a>]</p>

<p><strong>May 1, 2020:</strong> I’m giving a guest lecture on uncertainty-aware reinforcement learning to the advanced robotics class for graduate students at Stevens Institute of Technology. [<a href="/assets/slides/2020-advanced_robotics_lecture.pdf">slides</a>]</p>

<p><strong>March 13, 2020:</strong> Today I am showcasing my work on uncertainy-aware decision making as part of the <a href="https://www.nyas.org/events/2020/14th-annual-machine-learning-symposium/">New York Academy of Sciences’ 14th annual Machine Learning Symposium</a>. [<a href="/assets/posters/2020-martin_etal-poster.pdf">poster</a>]</p>

<p><strong>January 27, 2020:</strong> I am thrilled to announce that I will be working at <a href="https://deepmind.com">DeepMind</a> in Edmonton, Canada, as a research intern with <a href="https://scholar.google.com/citations?user=G3pvUNEAAAAJ&amp;hl=en">Joseph Modayil</a>. There I plan to study perception and discovery in the context of continual reinforcement learning.</p>

<p><strong>November 4, 2019:</strong> Visiting MIT to connect with <a href="https://tixiaoshan.github.io">Tixiao Shan</a> at <a href="https://www.csail.mit.edu">CSAIL</a> and learn about the <a href="http://roboat.org">Roboat project</a>. I’m giving a short talk to the group about my recent work.</p>

<p><strong>October 22, 2019:</strong> I’m giving a talk at <a href="http://deepmind.com">DeepMind</a> in Edmonton, Canada, about how RL agents can benefit from organizing their experience into contexts.</p>

<p><strong>October 7, 2019:</strong> Two of my projects will appear as NeurIPS workshop papers this year.   
   * <a href="https://sites.google.com/view/neurips19-safe-robust-workshop#h.p_iF36C6BL_elR">Saftey and Robust Decison Making Workshop</a>: Stochastically Dominant Distributional Reinforcement Learning, <strong>John D. Martin</strong>,  Michal Lyskawinski, Xiaohu Li, Brendan Englot.   
   * <a href="https://sites.google.com/view/biologicalandartificialrl">Biological and Artifical RL Workshop</a>: Memento: Further Progress through Forgetting, William Fedus, Dibya Ghosh, <strong>John D. Martin</strong>, Marc G. Bellemare, Hugo Larochelle, Yoshua Bengio.</p>

<p><strong>September 18, 2019:</strong> I’m giving a talk about the disparate impacts of alpine climbing as part of the <a href="https://americanalpineclub.org">American Alpine Club</a>’s Story Swap in Philadelphia <a href="https://www.phillychapter-aac.org/journal/2019/9/06/john">[link]</a>.</p>

<p><strong>August 30, 2019:</strong> I’m giving a talk at <a href="https://ai.google/research/teams/brain/robotics/">Google Robotics</a> in New York City on exploiting transition invariance for efficient Reinforcement Learning in multi-stage settings.</p>

<p><strong>July 19, 2019:</strong> I was featured in the journal of the <a href="https://americanalpineclub.org">American Alpine Club</a>’s Philadelphia chapter, as part of my work with their winter mountaineering mentorship program <a href="https://www.phillychapter-aac.org/journal/2019/6/29/mentoring-program-spotlight-john-martin">[link]</a>.</p>

<p><strong>March 14, 2019:</strong> I’m excited to announce that I will be working at <a href="https://ai.google/research/teams/brain">Google Brain</a> in Montréal, Canada, as a research intern with <a href="https://scholar.google.com/citations?user=uyYPun0AAAAJ&amp;hl=en#">Marc G. Bellemare</a>’s group. There I will study methods for continual reinforcement learning in deep neural networks, focusing on settings with non-stationary data.</p>


    </article>
    <span class="print-footer">News - john d. martin</span>
    <footer>
  <hr class="slender">
  <ul class="footer-links">
   
      <li>
        <a href="//www.twitter.com/jdmartin86"><span class="icon-twitter"></span></a>
      </li>
    
      <li>
        <a href="//github.com/jdmartin86"><span class="icon-github"></span></a>
      </li>
    
      <li>
        <a href="//scholar.google.com/citations?user=Jun8c34AAAAJ&hl=en"><span class="icon-google"></span></a>
      </li>
      
  </ul>
<div class="credits">
<span>&copy; 2022 &nbsp;&nbsp;JOHN D. MARTIN</span></br> <br>
<span>This site created with the <a href="//github.com/clayh53/tufte-jekyll">Tufte theme </a> in <a href="//jekyllrb.com">Jekyll</a>.</span> 
</div>  
</footer>

  </body>
</html>
